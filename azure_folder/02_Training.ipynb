{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Training\n",
        "\n",
        "In this notebook, we will learn how to train an AI model in the cloud.  \n",
        "There are a few things that are special regarding Cloud AI training, but also a lot of similarities between our old-school way of working."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Again let us start by setting some global parameters first"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1644064934267
        }
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32\n",
        "MAX_EPOCHS = 100\n",
        "PATIENCE = 11\n",
        "INITIAL_LEARNING_RATE = 0.01\n",
        "DROPOUTRATE = 0.0\n",
        "ACTIVATION_HIDDEN = 'relu' # activatiefunctie van de hidden layer neuronen\n",
        "ACTIVATION_OUTPUT = 'sigmoid'# activatie van de output layer neuronen\n",
        "INITIALIZER = 'RandomUniform' # type van kernel intializer\n",
        "model_name = 'sequences-nn'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "And of course importing the packages we need! Again, don't forget to set your kernel right in the top-right corner!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1644064934807
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import os\n",
        "from glob import glob\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import random\n",
        "SEED = 42   # set random seed\n",
        "random.seed(SEED)\n",
        "\n",
        "from typing import List"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1644064934979
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "## Import AzureML packages\n",
        "from azureml.core import Workspace\n",
        "from azureml.core import Dataset\n",
        "from azureml.data.datapath import DataPath\n",
        "from azureml.core.compute import AmlCompute\n",
        "from azureml.core.compute import ComputeTarget"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "One special import are these Utils scripts. You can read more about them in the `utils > utils.py` file. I have included them here to load them in. They contain some helper functions we will be needing later on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "gather": {
          "logged": 1644074588874
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from utils.utils import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Step 1: Connect Workspace"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Follow the same steps as the previous notebook, to set up your Workspace configuration!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1644066583008
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "## Either get environment variables, or a fallback name, which is the second parameter.\n",
        "## Currently, fill in the fallback values. Later on, we will make sure to work with Environment values. So we're already preparing for it in here!\n",
        "workspace_name = os.environ.get('WORKSPACE', 'hermans-cedric-ml')\n",
        "subscription_id = os.environ.get('SUBSCRIPTION_ID', '51f06efd-190a-4388-8d72-41669512398d')\n",
        "resource_group = os.environ.get('RESOURCE_GROUP', '04-AzureML')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1644066589903
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "ws = Workspace.get(name=workspace_name,\n",
        "               subscription_id=subscription_id,\n",
        "               resource_group=resource_group)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Step 1.1 -- Create Compute Cluster\n",
        "\n",
        "A Compute Cluster is a combination of multiple Compute Instances. Azure will scale these machines according to the number of nodes we fill into the configuration.  \n",
        "Based on the amount of Jobs we want to run in parallel, multiple machines will be created.\n",
        "\n",
        "We choose to define a minimum of 0 machines, which means Azure will need some time to create at least one machine everytime we need one.\n",
        "If you keep the minimum on 1, you always have one that's ready for your development.\n",
        "The timeout time to scale down back to 0 machines can also be configured if required."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1644066602095
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "found compute target: cpu-cluster\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# choose a name for your cluster\n",
        "compute_name = os.environ.get(\"AML_COMPUTE_CLUSTER_NAME\", \"cpu-cluster\")\n",
        "compute_min_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MIN_NODES\", 0)\n",
        "compute_max_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MAX_NODES\", 4)\n",
        "\n",
        "# This example uses CPU VM. For using GPU VM, set SKU to STANDARD_NC6\n",
        "vm_size = os.environ.get(\"AML_COMPUTE_CLUSTER_SKU\", \"STANDARD_D2_V2\")\n",
        "\n",
        "\n",
        "if compute_name in ws.compute_targets:\n",
        "    compute_target = ws.compute_targets[compute_name]\n",
        "    if compute_target and type(compute_target) is AmlCompute:\n",
        "        print(\"found compute target: \" + compute_name)\n",
        "else:\n",
        "    print(\"creating new compute target...\")\n",
        "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = vm_size,\n",
        "                                                                min_nodes = compute_min_nodes, \n",
        "                                                                max_nodes = compute_max_nodes)\n",
        "\n",
        "    # create the cluster\n",
        "    compute_target = ComputeTarget.create(ws, compute_name, provisioning_config)\n",
        "    \n",
        "    # can poll for a minimum number of nodes and for a specific timeout. \n",
        "    # if no min node count is provided it will use the scale settings for the cluster\n",
        "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
        "    \n",
        "     # For a more detailed view of current AmlCompute status, use get_status()\n",
        "    print(compute_target.get_status().serialize())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Find and download datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1644066604783
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{ 'NRPS': DatasetRegistration(id='cd0e7d4c-fd07-4538-8df1-5344ac913e2b', name='NRPS', version=1, description='', tags={}),\n",
            "  'PKS': DatasetRegistration(id='019c4c3d-8a82-4260-98ce-2e3047dc8170', name='PKS', version=1, description='', tags={}),\n",
            "  'animals-testing-set': DatasetRegistration(id='b8ec1966-c9da-4ca9-b07d-e41ee35f5e07', name='animals-testing-set', version=1, description='The Animal Images to test, resized tot 64, 64', tags={'animals': 'cats,dogs,pandas', 'AI-Model': 'CNN', 'Split size': '0.2', 'type': 'testing'}),\n",
            "  'animals-training-set': DatasetRegistration(id='02ab0351-03ab-4e0e-b42f-620fa183bd4d', name='animals-training-set', version=1, description='The Animal Images to train, resized tot 64, 64', tags={'animals': 'cats,dogs,pandas', 'AI-Model': 'CNN', 'Split size': '0.8', 'type': 'training'}),\n",
            "  'cats': DatasetRegistration(id='db847d56-0389-43e8-93aa-6cd3df7507c7', name='cats', version=1, description='', tags={}),\n",
            "  'dogs': DatasetRegistration(id='1f40c908-e568-4434-a620-5b77cc638116', name='dogs', version=1, description='', tags={}),\n",
            "  'pandas': DatasetRegistration(id='c50be40f-bbb1-406a-8c39-1fc41d67f8dc', name='pandas', version=1, description='', tags={}),\n",
            "  'processed_NRPS': DatasetRegistration(id='9f2904c6-5432-43cc-9f87-173e8c9a387a', name='processed_NRPS', version=1, description='NRPS sequences processed to amino acid counts', tags={'genes': 'NRPS', 'AI-Model': 'NN'}),\n",
            "  'processed_PKS': DatasetRegistration(id='81f4fa96-08ae-478b-a845-a6bf7090a743', name='processed_PKS', version=1, description='PKS sequences processed to amino acid counts', tags={'genes': 'PKS', 'AI-Model': 'NN'}),\n",
            "  'resized_cats': DatasetRegistration(id='765d46f3-ce50-47aa-bae9-4875c1892305', name='resized_cats', version=1, description='cats images resized tot 64, 64', tags={'animals': 'cats', 'AI-Model': 'CNN'}),\n",
            "  'resized_dogs': DatasetRegistration(id='eb4cd0d9-f2b8-4537-b86a-0868ae1dd7be', name='resized_dogs', version=1, description='dogs images resized tot 64, 64', tags={'animals': 'dogs', 'AI-Model': 'CNN'}),\n",
            "  'resized_pandas': DatasetRegistration(id='4a83c752-3e9c-4ec8-b603-addacdb916de', name='resized_pandas', version=1, description='pandas images resized tot 64, 64', tags={'animals': 'pandas', 'AI-Model': 'CNN'})}\n"
          ]
        }
      ],
      "source": [
        "datasets = Dataset.get_all(workspace=ws) # Make sure to give our workspace with it\n",
        "print(datasets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Step 2: Create an AI model and training code\n",
        "\n",
        "We will first create an AI model to use in our training script.  \n",
        "A basic AI model has been given in the /utils/utils.py directory. You can change it there if you want to\n",
        "\n",
        "In this step, we will also configure a Training script. This script is an Executable Python script.  \n",
        "This is slightly different from our other way of working, where we work with Notebooks.\n",
        "\n",
        "Because Azure will be launching and running our Python scripts, we need to create one file that can be executed in one go.\n",
        "This needs all our imports, packages, data ... ready without manual interference."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "We'll store all of these files into a scripts directory. That way we can upload that directory to our training VM later."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Step 2.1 -- Prepare the scripts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "gather": {
          "logged": 1644074597720
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "script_folder = os.path.join(os.getcwd(), 'scripts')\n",
        "os.makedirs(script_folder, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting /mnt/batch/tasks/shared/LS_root/mounts/clusters/compute-ch/code/Users/cedric.hermans2/AzureML-assignment/scripts/train.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile $script_folder/train.py\n",
        "\n",
        "import argparse\n",
        "import os\n",
        "from glob import glob\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# This time we will need our Tensorflow Keras libraries, as we will be working with the AI training now\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "# This AzureML package will allow to log our metrics etc.\n",
        "from azureml.core import Run\n",
        "\n",
        "# Important to load in the utils as well!\n",
        "from utils import *\n",
        "\n",
        "\n",
        "### HARDCODED VARIABLES FOR NOW\n",
        "### TODO for the students:\n",
        "### Make sure to adapt the ArgumentParser on line 31 to include these parameters\n",
        "### You can base your answer on the lines that are already there\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "MAX_EPOCHS = 100\n",
        "PATIENCE = 11\n",
        "INITIAL_LEARNING_RATE = 0.01\n",
        "DROPOUTRATE = 0.0\n",
        "ACTIVATION_HIDDEN = 'relu' # activatiefunctie van de hidden layer neuronen\n",
        "ACTIVATION_OUTPUT = 'sigmoid'# activatie van de output layer neuronen\n",
        "INITIALIZER = 'RandomUniform' # type van kernel intializer\n",
        "model_name = 'gene-cnn-test'\n",
        "\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--data-folder', type=str, dest='data_folder', help='data folder mounting point')\n",
        "parser.add_argument('--epochs', type=int, dest='epochs', help='The amount of Epochs to train')\n",
        "parser.add_argument('--initial-lr', type=float, dest='initial_learning_rate', help='The initial learning rate')\n",
        "parser.add_argument('--batch-size', type=int, dest='batch_size', help='The batch size')\n",
        "args = parser.parse_args()\n",
        "\n",
        "\n",
        "data_folder = args.data_folder\n",
        "print('Training folder:', data_folder)\n",
        "\n",
        "INITIAL_LEARNING_RATE = args.initial_learning_rate\n",
        "MAX_EPOCHS = args.epochs\n",
        "BATCH_SIZE = args.batch_size\n",
        "\n",
        "# As we're mounting the training_folder and testing_folder onto the `/mnt/data` directories, we can load in the sequences by using glob.\n",
        "X_paths = glob(os.path.join('/mnt/data', '**', '*X.np'), recursive=True)\n",
        "y_paths = glob(os.path.join('/mnt/data', '**', '*y.np'), recursive=True)\n",
        "\n",
        "print(\"features samples:\", len(X_paths))\n",
        "print(X_paths)\n",
        "print(\"target samples:\", len(y_paths))\n",
        "print(y_paths)\n",
        "\n",
        "X=[]\n",
        "y=[]\n",
        "\n",
        "for xf in X_paths:\n",
        "    X+=list(np.loadtxt(xf))\n",
        "for yf in y_paths:\n",
        "    y+=list(np.loadtxt(yf))\n",
        "X_train,X_test,y_train,y_test=train_test_split(np.array(X),np.array(y),test_size=0.2)\n",
        "\n",
        "\n",
        "print('Shapes:')\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(len(y_train))\n",
        "print(len(y_test))\n",
        "\n",
        "# Create an output directory where our AI model will be saved to.\n",
        "# Everything inside the `outputs` directory will be logged and kept aside for later usage.\n",
        "model_path = os.path.join('outputs', model_name)\n",
        "os.makedirs(model_path, exist_ok=True)\n",
        "\n",
        "## START OUR RUN context.\n",
        "## We can now log interesting information to Azure, by using these methods.\n",
        "run = Run.get_context()\n",
        "\n",
        "# Save the best model, not the last\n",
        "cb_save_best_model = keras.callbacks.ModelCheckpoint(filepath=model_path,\n",
        "                                                         monitor='val_loss', \n",
        "                                                         save_best_only=True, \n",
        "                                                         verbose=1)\n",
        "\n",
        "# Early stop when the val_los isn't improving for PATIENCE epochs\n",
        "cb_early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', \n",
        "                                              patience= PATIENCE,\n",
        "                                              verbose=1,\n",
        "                                              restore_best_weights=True)\n",
        "\n",
        "# Reduce the Learning Rate when not learning more for 4 epochs.\n",
        "cb_reduce_lr_on_plateau = keras.callbacks.ReduceLROnPlateau(factor=.5, patience=4, verbose=1)\n",
        "\n",
        "opt = SGD(learning_rate=INITIAL_LEARNING_RATE, decay=INITIAL_LEARNING_RATE / MAX_EPOCHS) # Define the Optimizer\n",
        "\n",
        "model = buildModel(20, 2) # Create the AI model as defined in the utils script.\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
        "\n",
        "# train the network\n",
        "history = model.fit(X_train, y_train, batch_size=BATCH_SIZE,\n",
        "                        validation_data=(X_test, y_test),\n",
        "                        epochs=MAX_EPOCHS,\n",
        "                        callbacks=[cb_save_best_model, cb_early_stop, cb_reduce_lr_on_plateau] )\n",
        "run.log_list('val_loss', history.history['val_loss'])\n",
        "run.log_list('val_accuracy', history.history['val_accuracy'])\n",
        "run.log(\"history\",history.history)\n",
        "\n",
        "print(\"[INFO] evaluating network...\")\n",
        "predictions = model.predict(X_test, batch_size=32)\n",
        "print(classification_report(y_test.argmax(axis=1), predictions.argmax(axis=1), target_names=['NRPS', 'PKS'])) # Give the target names to easier refer to them.\n",
        "# If you want, you can enter the target names as a parameter as well, in case you ever adapt your AI model to more genes.\n",
        "\n",
        "cf_matrix = confusion_matrix(y_test.argmax(axis=1), predictions.argmax(axis=1))\n",
        "print(cf_matrix)\n",
        "\n",
        "### TODO for students\n",
        "### Find a way to log more information to the Run context.\n",
        "\n",
        "# Save the confusion matrix to the outputs.\n",
        "np.save('outputs/confusion_matrix.npy', cf_matrix)\n",
        "\n",
        "print(\"DONE TRAINING\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "gather": {
          "logged": 1644075354801
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/mnt/batch/tasks/shared/LS_root/mounts/clusters/compute-ch/code/Users/cedric.hermans2/AzureML-assignment/scripts/utils.py'"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Copy the Utils file into the script_folder\n",
        "import shutil\n",
        "shutil.copy('utils/utils.py', script_folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Step 2.2 -- Prepare the environment\n",
        "\n",
        "The training script we have just defined still needs some more information before we can start it.  \n",
        "We'll need to define it's Anaconda or Pip environment with all the packages that should be installed prior to training.  \n",
        "We can re-use the environments later, or we can use environments other people have created for us.\n",
        "\n",
        "You can also customize the Base Docker image to train on, if you prefer. I won't use this in here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1644068216756
        },
        "jupyter": {
          "outputs_hidden": true,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{\n",
              "    \"databricks\": {\n",
              "        \"eggLibraries\": [],\n",
              "        \"jarLibraries\": [],\n",
              "        \"mavenLibraries\": [],\n",
              "        \"pypiLibraries\": [],\n",
              "        \"rcranLibraries\": []\n",
              "    },\n",
              "    \"docker\": {\n",
              "        \"arguments\": [],\n",
              "        \"baseDockerfile\": null,\n",
              "        \"baseImage\": \"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20211124.v1\",\n",
              "        \"baseImageRegistry\": {\n",
              "            \"address\": null,\n",
              "            \"password\": null,\n",
              "            \"registryIdentity\": null,\n",
              "            \"username\": null\n",
              "        },\n",
              "        \"enabled\": false,\n",
              "        \"platform\": {\n",
              "            \"architecture\": \"amd64\",\n",
              "            \"os\": \"Linux\"\n",
              "        },\n",
              "        \"sharedVolumes\": true,\n",
              "        \"shmSize\": null\n",
              "    },\n",
              "    \"environmentVariables\": {\n",
              "        \"EXAMPLE_ENV_VAR\": \"EXAMPLE_VALUE\"\n",
              "    },\n",
              "    \"inferencingStackVersion\": null,\n",
              "    \"name\": \"genes-classification-env-training\",\n",
              "    \"python\": {\n",
              "        \"baseCondaEnvironment\": null,\n",
              "        \"condaDependencies\": {\n",
              "            \"channels\": [\n",
              "                \"anaconda\",\n",
              "                \"conda-forge\"\n",
              "            ],\n",
              "            \"dependencies\": [\n",
              "                \"python=3.6.2\",\n",
              "                {\n",
              "                    \"pip\": [\n",
              "                        \"azureml-dataset-runtime[pandas,fuse]~=1.37.0\",\n",
              "                        \"azureml-defaults~=1.37.0\",\n",
              "                        \"tensorflow\",\n",
              "                        \"scikit-learn\",\n",
              "                        \"opencv-python-headless\"\n",
              "                    ]\n",
              "                }\n",
              "            ],\n",
              "            \"name\": \"azureml_cf7bc5a038f0d79aaaf5515c9290adf2\"\n",
              "        },\n",
              "        \"condaDependenciesFile\": null,\n",
              "        \"interpreterPath\": \"python\",\n",
              "        \"userManagedDependencies\": false\n",
              "    },\n",
              "    \"r\": null,\n",
              "    \"spark\": {\n",
              "        \"packages\": [],\n",
              "        \"precachePackages\": true,\n",
              "        \"repositories\": []\n",
              "    },\n",
              "    \"version\": \"1\"\n",
              "}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from azureml.core.environment import Environment\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "\n",
        "# Create an Environment name for later use\n",
        "environment_name = os.environ.get('TRAINING_ENV_NAME', 'genes-classification-env-training')\n",
        "env = Environment(environment_name)\n",
        "\n",
        "# It's called CondaDependencies, but you can also use pip packages ;-)\n",
        "env.python.conda_dependencies = CondaDependencies.create(\n",
        "        # Using opencv-python-headless is interesting to skip the overhead of packages that we don't need in a headless-VM.\n",
        "        pip_packages=['azureml-dataset-runtime[pandas,fuse]', 'azureml-defaults', 'tensorflow', 'scikit-learn', 'opencv-python-headless']\n",
        "    )\n",
        "# Register environment to re-use later\n",
        "env.register(workspace = ws)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Step 2.3 -- Prepare the ScriptRunConfig\n",
        "\n",
        "A **ScriptRunConfig** is a configuration that contains all the information needed to launch a Job inside an Experiment.\n",
        "This contains information to the directory of scripts it should use, the **name** of the script to start,\n",
        "the **arguments** to pass into that script, the **compute** target to run the script on, and finally the **environment** to run it on.\n",
        "\n",
        "We then need to attach such a ScriptRunConfig onto an Experiment on Azure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "gather": {
          "logged": 1644074862097
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "features samples: 0\n",
            "target samples: 0\n"
          ]
        }
      ],
      "source": [
        "datasets['processed_genes'].as_mount('/mnt/data/')\n",
        "# As we're mounting the training_folder and testing_folder onto the `/mnt/data` directories, we can load in the sequences by using glob.\n",
        "X_paths = glob(os.path.join('/mnt/data','**', '*X.np'), recursive=True)\n",
        "y_paths = glob(os.path.join('/mnt/data','**', '*y.np'), recursive=True)\n",
        "\n",
        "print(\"features samples:\", len(X_paths))\n",
        "print(\"target samples:\", len(y_paths))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "gather": {
          "logged": 1644075755753
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Run started!\n",
            "Run started!\n",
            "Run started!\n",
            "Run started!\n",
            "Run started!\n",
            "Run started!\n",
            "Run started!\n",
            "Run started!\n",
            "Run started!\n",
            "Run started!\n",
            "Run started!\n",
            "Run started!\n",
            "Run started!\n",
            "Run started!\n",
            "Run started!\n",
            "Run started!\n",
            "Run started!\n",
            "Run started!\n",
            "Run started!\n",
            "Run started!\n",
            "Run started!\n",
            "Run started!\n",
            "Run started!\n",
            "Run started!\n",
            "Run started!\n",
            "Run started!\n",
            "Run started!\n",
            "Run started!\n",
            "Run started!\n",
            "Run started!\n",
            "Run started!\n",
            "Run started!\n",
            "Run started!\n",
            "Run started!\n",
            "Run started!\n",
            "Run started!\n",
            "Run started!\n",
            "Run started!\n",
            "Run started!\n",
            "Run started!\n",
            "Run started!\n",
            "Run started!\n",
            "Run started!\n",
            "Run started!\n",
            "Run started!\n",
            "Run started!\n",
            "Run started!\n",
            "Run started!\n",
            "Run started!\n",
            "Run started!\n",
            "Run started!\n",
            "Run started!\n",
            "Run started!\n",
            "Run started!\n",
            "Run started!\n",
            "Run started!\n",
            "Run started!\n",
            "Run started!\n",
            "Run started!\n",
            "Run started!\n",
            "Run started!\n",
            "Run started!\n",
            "Run started!\n",
            "Run started!\n"
          ]
        }
      ],
      "source": [
        "from azureml.core import ScriptRunConfig\n",
        "from azureml.core import Experiment\n",
        "\n",
        "experiment_name = os.environ.get('EXPERIMENT_NAME', 'Genes-Classification')\n",
        "\n",
        "exp = Experiment(workspace=ws, name=experiment_name) # Create a new experiment\n",
        "\n",
        "experiment_runs = []\n",
        "\n",
        "# We can start four experiments for a bunch of different epoch options\n",
        "for epochs in [25, 50, 75, 100]:\n",
        "    for initial_learning_rate in [0.3,0.1, 0.05, 0.01]:\n",
        "        for batch_size in [16,32,64,128]:\n",
        "            args = [\n",
        "                '--data-folder', datasets['processed_genes'].as_mount('/mnt/data/'),\n",
        "                '--epochs', epochs,\n",
        "                '--initial-lr', initial_learning_rate,\n",
        "                '--batch-size', batch_size]\n",
        "\n",
        "            script_run_config = ScriptRunConfig(source_directory=script_folder,\n",
        "                            script='train.py', \n",
        "                            arguments=args,\n",
        "                            compute_target=compute_target,\n",
        "                            environment=env)\n",
        "\n",
        "            run = exp.submit(config=script_run_config)\n",
        "            experiment_runs.append(run) # Append it to our list of experiment runs for now. This is easy for referring later!\n",
        "            print('Run started!')\n",
        "\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Step 2.4 -- Await the results!\n",
        "\n",
        "Now that our experiment runs are starting, we can await the logs and results.  \n",
        "It can take a while to run everything, but the 4 jobs should run in Parallel, if all was well configured!\n",
        "\n",
        "The cells below can help you in viewing the results, while you head out for a coffee!\n",
        "\n",
        "I use the `experiment_runs[0]` as our run to log. It's the first one that was started.\n",
        "\n",
        "There are a few different options for each to select the one they prefer :-)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#### Step 2.4.1 -- Plain text output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1641670414098
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RunId: Genes-Classification_1644069031_cffbc973\n",
            "Web View: https://ml.azure.com/runs/Genes-Classification_1644069031_cffbc973?wsid=/subscriptions/51f06efd-190a-4388-8d72-41669512398d/resourcegroups/04-AzureML/workspaces/hermans-cedric-ml&tid=4ded4bb1-6bff-42b3-aed7-6a36a503bf7a\n",
            "\n",
            "Streaming azureml-logs/20_image_build_log.txt\n",
            "=============================================\n",
            "\n",
            "2022/02/05 13:50:37 Downloading source code...\n",
            "2022/02/05 13:50:38 Finished downloading source code\n",
            "2022/02/05 13:50:39 Creating Docker network: acb_default_network, driver: 'bridge'\n",
            "2022/02/05 13:50:39 Successfully set up Docker network: acb_default_network\n",
            "2022/02/05 13:50:39 Setting up Docker configuration...\n",
            "2022/02/05 13:50:40 Successfully set up Docker configuration\n",
            "2022/02/05 13:50:40 Logging in to registry: 4bc96a278283483f8523a427ca6960f3.azurecr.io\n",
            "2022/02/05 13:50:40 Successfully logged into 4bc96a278283483f8523a427ca6960f3.azurecr.io\n",
            "2022/02/05 13:50:40 Executing step ID: acb_step_0. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
            "2022/02/05 13:50:40 Scanning for dependencies...\n",
            "2022/02/05 13:50:41 Successfully scanned dependencies\n",
            "2022/02/05 13:50:41 Launching container with name: acb_step_0\n",
            "Sending build context to Docker daemon  66.56kB\n",
            "\n",
            "Step 1/21 : FROM mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20211124.v1@sha256:4a11079816df82134801c513f323799acad2cbef525ef7a5361278d9b74b1d14\n",
            "mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20211124.v1@sha256:4a11079816df82134801c513f323799acad2cbef525ef7a5361278d9b74b1d14: Pulling from azureml/openmpi3.1.2-ubuntu18.04\n",
            "284055322776: Already exists\n",
            "56c2761c3a56: Pulling fs layer\n",
            "e7dff8330ff9: Pulling fs layer\n",
            "c782690959f6: Pulling fs layer\n",
            "722c34119f7e: Pulling fs layer\n",
            "2df507734fe8: Pulling fs layer\n",
            "858f3d745b66: Pulling fs layer\n",
            "7c1ed34d7266: Pulling fs layer\n",
            "1ef5f8a4fad5: Pulling fs layer\n",
            "722c34119f7e: Waiting\n",
            "2df507734fe8: Waiting\n",
            "858f3d745b66: Waiting\n",
            "7c1ed34d7266: Waiting\n",
            "1ef5f8a4fad5: Waiting\n",
            "e7dff8330ff9: Verifying Checksum\n",
            "e7dff8330ff9: Download complete\n",
            "c782690959f6: Verifying Checksum\n",
            "c782690959f6: Download complete\n",
            "2df507734fe8: Verifying Checksum\n",
            "2df507734fe8: Download complete\n",
            "56c2761c3a56: Verifying Checksum\n",
            "56c2761c3a56: Download complete\n",
            "7c1ed34d7266: Verifying Checksum\n",
            "7c1ed34d7266: Download complete\n",
            "1ef5f8a4fad5: Verifying Checksum\n",
            "1ef5f8a4fad5: Download complete\n",
            "858f3d745b66: Verifying Checksum\n",
            "858f3d745b66: Download complete\n",
            "722c34119f7e: Verifying Checksum\n",
            "722c34119f7e: Download complete\n",
            "56c2761c3a56: Pull complete\n",
            "e7dff8330ff9: Pull complete\n",
            "c782690959f6: Pull complete\n",
            "722c34119f7e: Pull complete\n",
            "2df507734fe8: Pull complete\n",
            "858f3d745b66: Pull complete\n",
            "7c1ed34d7266: Pull complete\n",
            "1ef5f8a4fad5: Pull complete\n",
            "Digest: sha256:4a11079816df82134801c513f323799acad2cbef525ef7a5361278d9b74b1d14\n",
            "Status: Downloaded newer image for mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20211124.v1@sha256:4a11079816df82134801c513f323799acad2cbef525ef7a5361278d9b74b1d14\n",
            " ---> 332d3aa8a60a\n",
            "Step 2/21 : USER root\n",
            " ---> Running in cf0374a41e26\n",
            "Removing intermediate container cf0374a41e26\n",
            " ---> 077d4d10a51b\n",
            "Step 3/21 : RUN mkdir -p $HOME/.cache\n",
            " ---> Running in 3af06fb35bc0\n",
            "Removing intermediate container 3af06fb35bc0\n",
            " ---> 61bfc930ee69\n",
            "Step 4/21 : WORKDIR /\n",
            " ---> Running in 44d675c39d4b\n",
            "Removing intermediate container 44d675c39d4b\n",
            " ---> e564e90096fb\n",
            "Step 5/21 : COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\n",
            " ---> 4bc63e87137d\n",
            "Step 6/21 : RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.11; then conda install conda==4.4.11; fi\n",
            " ---> Running in e30aa84d3c98\n",
            "Removing intermediate container e30aa84d3c98\n",
            " ---> 5a7aeb59d5c1\n",
            "Step 7/21 : COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\n",
            " ---> ee102be517de\n",
            "Step 8/21 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_cf7bc5a038f0d79aaaf5515c9290adf2 -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \"$HOME/.cache/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\n",
            " ---> Running in 453cb9a2df2b\n",
            "Warning: you have pip-installed dependencies in your environment file, but you do not list pip itself as one of your conda dependencies.  Conda may not use the correct pip to install your packages, and they may end up in the wrong place.  Please add an explicit pip dependency.  I'm adding one for you, but still nagging you.\n",
            "Collecting package metadata (repodata.json): ...working... \n",
            "done\n",
            "Solving environment: ...working... done\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "\n",
            "pip-20.2.4           | 2.0 MB    |            |   0% \n",
            "pip-20.2.4           | 2.0 MB    | ##5        |  26% \n",
            "pip-20.2.4           | 2.0 MB    | ########## | 100% \n",
            "pip-20.2.4           | 2.0 MB    | ########## | 100% \n",
            "\n",
            "libedit-3.1          | 171 KB    |            |   0% \n",
            "libedit-3.1          | 171 KB    | ########## | 100% \n",
            "\n",
            "ncurses-6.0          | 907 KB    |            |   0% \n",
            "ncurses-6.0          | 907 KB    | ########## | 100% \n",
            "ncurses-6.0          | 907 KB    | ########## | 100% \n",
            "\n",
            "tk-8.6.10            | 3.2 MB    |            |   0% \n",
            "tk-8.6.10            | 3.2 MB    | ########## | 100% \n",
            "tk-8.6.10            | 3.2 MB    | ########## | 100% \n",
            "\n",
            "zlib-1.2.11          | 120 KB    |            |   0% \n",
            "zlib-1.2.11          | 120 KB    | ########## | 100% \n",
            "\n",
            "readline-7.0         | 387 KB    |            |   0% \n",
            "readline-7.0         | 387 KB    | ########## | 100% \n",
            "\n",
            "wheel-0.35.1         | 36 KB     |            |   0% \n",
            "wheel-0.35.1         | 36 KB     | ########## | 100% \n",
            "\n",
            "xz-5.2.5             | 438 KB    |            |   0% \n",
            "xz-5.2.5             | 438 KB    | ########## | 100% \n",
            "xz-5.2.5             | 438 KB    | ########## | 100% \n",
            "\n",
            "ca-certificates-2020 | 128 KB    |            |   0% \n",
            "ca-certificates-2020 | 128 KB    | ########## | 100% \n",
            "\n",
            "sqlite-3.23.1        | 1.5 MB    |            |   0% \n",
            "sqlite-3.23.1        | 1.5 MB    | ########## | 100% \n",
            "sqlite-3.23.1        | 1.5 MB    | ########## | 100% \n",
            "\n",
            "openssl-1.0.2u       | 3.1 MB    |            |   0% \n",
            "openssl-1.0.2u       | 3.1 MB    | #######9   |  79% \n",
            "openssl-1.0.2u       | 3.1 MB    | ########## | 100% \n",
            "\n",
            "certifi-2020.6.20    | 160 KB    |            |   0% \n",
            "certifi-2020.6.20    | 160 KB    | ########## | 100% \n",
            "\n",
            "libstdcxx-ng-9.1.0   | 4.0 MB    |            |   0% \n",
            "libstdcxx-ng-9.1.0   | 4.0 MB    | ########## | 100% \n",
            "libstdcxx-ng-9.1.0   | 4.0 MB    | ########## | 100% \n",
            "\n",
            "libgcc-ng-9.1.0      | 8.1 MB    |            |   0% \n",
            "libgcc-ng-9.1.0      | 8.1 MB    | ##8        |  29% \n",
            "libgcc-ng-9.1.0      | 8.1 MB    | ########## | 100% \n",
            "libgcc-ng-9.1.0      | 8.1 MB    | ########## | 100% \n",
            "\n",
            "python-3.6.2         | 27.0 MB   |            |   0% \n",
            "python-3.6.2         | 27.0 MB   |            |   1% \n",
            "python-3.6.2         | 27.0 MB   | #7         |  18% \n",
            "python-3.6.2         | 27.0 MB   | ###4       |  34% \n",
            "python-3.6.2         | 27.0 MB   | #####9     |  60% \n",
            "python-3.6.2         | 27.0 MB   | #######9   |  80% \n",
            "python-3.6.2         | 27.0 MB   | #########6 |  96% \n",
            "python-3.6.2         | 27.0 MB   | ########## | 100% \n",
            "\n",
            "setuptools-50.3.0    | 891 KB    |            |   0% \n",
            "setuptools-50.3.0    | 891 KB    | ########## | 100% \n",
            "setuptools-50.3.0    | 891 KB    | ########## | 100% \n",
            "\n",
            "libffi-3.2.1         | 52 KB     |            |   0% \n",
            "libffi-3.2.1         | 52 KB     | ########## | 100% \n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "Installing pip dependencies: ...working... \n",
            "Ran pip subprocess with arguments:\n",
            "['/azureml-envs/azureml_cf7bc5a038f0d79aaaf5515c9290adf2/bin/python', '-m', 'pip', 'install', '-U', '-r', '/azureml-environment-setup/condaenv.bh1el8w5.requirements.txt']\n",
            "Pip subprocess output:\n",
            "Collecting azureml-dataset-runtime[fuse,pandas]~=1.37.0\n",
            "  Downloading azureml_dataset_runtime-1.37.0-py3-none-any.whl (3.5 kB)\n",
            "Collecting azureml-defaults~=1.37.0\n",
            "  Downloading azureml_defaults-1.37.0-py3-none-any.whl (3.0 kB)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.6.2-cp36-cp36m-manylinux2010_x86_64.whl (458.3 MB)\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-0.24.2-cp36-cp36m-manylinux2010_x86_64.whl (22.2 MB)\n",
            "Collecting opencv-python-headless\n",
            "  Downloading opencv_python_headless-4.5.5.62-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.7 MB)\n",
            "Collecting azureml-dataprep<2.26.0a,>=2.25.0a\n",
            "  Downloading azureml_dataprep-2.25.2-py3-none-any.whl (39.4 MB)\n",
            "Collecting pyarrow<4.0.0,>=0.17.0\n",
            "  Downloading pyarrow-3.0.0-cp36-cp36m-manylinux2014_x86_64.whl (20.7 MB)\n",
            "Collecting numpy!=1.19.3; sys_platform == \"linux\"\n",
            "  Downloading numpy-1.19.5-cp36-cp36m-manylinux2010_x86_64.whl (14.8 MB)\n",
            "Collecting fusepy<4.0.0,>=3.0.1; extra == \"fuse\"\n",
            "  Downloading fusepy-3.0.1.tar.gz (11 kB)\n",
            "Collecting pandas<2.0.0,>=0.23.4; extra == \"pandas\"\n",
            "  Downloading pandas-1.1.5-cp36-cp36m-manylinux1_x86_64.whl (9.5 MB)\n",
            "Collecting azureml-inference-server-http~=0.4.1\n",
            "  Downloading azureml_inference_server_http-0.4.2-py3-none-any.whl (38 kB)\n",
            "Collecting json-logging-py==0.2\n",
            "  Downloading json-logging-py-0.2.tar.gz (3.6 kB)\n",
            "Collecting configparser==3.7.4\n",
            "  Downloading configparser-3.7.4-py2.py3-none-any.whl (22 kB)\n",
            "Collecting azureml-core~=1.37.0\n",
            "  Downloading azureml_core-1.37.0.post2-py3-none-any.whl (2.5 MB)\n",
            "Collecting grpcio<2.0,>=1.37.0\n",
            "  Downloading grpcio-1.43.0-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
            "Collecting opt-einsum~=3.3.0\n",
            "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
            "Collecting h5py~=3.1.0\n",
            "  Downloading h5py-3.1.0-cp36-cp36m-manylinux1_x86_64.whl (4.0 MB)\n",
            "Collecting clang~=5.0\n",
            "  Downloading clang-5.0.tar.gz (30 kB)\n",
            "Collecting protobuf>=3.9.2\n",
            "  Downloading protobuf-3.19.4-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "Collecting keras-preprocessing~=1.1.2\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "Collecting keras<2.7,>=2.6.0\n",
            "  Downloading keras-2.6.0-py2.py3-none-any.whl (1.3 MB)\n",
            "Collecting tensorboard<2.7,>=2.6.0\n",
            "  Downloading tensorboard-2.6.0-py3-none-any.whl (5.6 MB)\n",
            "Collecting termcolor~=1.1.0\n",
            "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
            "Collecting astunparse~=1.6.3\n",
            "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Collecting gast==0.4.0\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Collecting google-pasta~=0.2\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "Collecting six~=1.15.0\n",
            "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
            "Collecting tensorflow-estimator<2.7,>=2.6.0\n",
            "  Downloading tensorflow_estimator-2.6.0-py2.py3-none-any.whl (462 kB)\n",
            "Collecting flatbuffers~=1.12.0\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Collecting absl-py~=0.10\n",
            "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
            "Collecting typing-extensions~=3.7.4\n",
            "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied, skipping upgrade: wheel~=0.35 in /azureml-envs/azureml_cf7bc5a038f0d79aaaf5515c9290adf2/lib/python3.6/site-packages (from tensorflow->-r /azureml-environment-setup/condaenv.bh1el8w5.requirements.txt (line 3)) (0.35.1)\n",
            "Collecting wrapt~=1.12.1\n",
            "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
            "Collecting joblib>=0.11\n",
            "  Downloading joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting scipy>=0.19.1\n",
            "  Downloading scipy-1.5.4-cp36-cp36m-manylinux1_x86_64.whl (25.9 MB)\n",
            "Collecting dotnetcore2<3.0.0,>=2.1.14\n",
            "  Downloading dotnetcore2-2.1.23-py3-none-manylinux1_x86_64.whl (29.3 MB)\n",
            "Collecting azureml-dataprep-native<39.0.0,>=38.0.0\n",
            "  Downloading azureml_dataprep_native-38.0.0-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)\n",
            "Collecting cloudpickle<2.0.0,>=1.1.0\n",
            "  Downloading cloudpickle-1.6.0-py3-none-any.whl (23 kB)\n",
            "Collecting azureml-dataprep-rslex~=2.1.0dev0\n",
            "  Downloading azureml_dataprep_rslex-2.1.1-cp36-cp36m-manylinux2010_x86_64.whl (13.2 MB)\n",
            "Collecting azure-identity==1.7.0\n",
            "  Downloading azure_identity-1.7.0-py2.py3-none-any.whl (129 kB)\n",
            "Collecting python-dateutil>=2.7.3\n",
            "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
            "Collecting pytz>=2017.2\n",
            "  Downloading pytz-2021.3-py2.py3-none-any.whl (503 kB)\n",
            "Collecting inference-schema==1.3.0\n",
            "  Downloading inference_schema-1.3.0-py3-none-any.whl (19 kB)\n",
            "Collecting applicationinsights>=0.11.7\n",
            "  Downloading applicationinsights-0.11.10-py2.py3-none-any.whl (55 kB)\n",
            "Collecting gunicorn==20.1.0; platform_system != \"Windows\"\n",
            "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
            "Collecting flask==1.0.3\n",
            "  Downloading Flask-1.0.3-py2.py3-none-any.whl (92 kB)\n",
            "Collecting jsonpickle<3.0.0\n",
            "  Downloading jsonpickle-2.1.0-py2.py3-none-any.whl (38 kB)\n",
            "Collecting knack~=0.8.2\n",
            "  Downloading knack-0.8.2-py3-none-any.whl (59 kB)\n",
            "Collecting requests[socks]<3.0.0,>=2.19.1\n",
            "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
            "Collecting azure-mgmt-storage<20.0.0,>=16.0.0\n",
            "  Downloading azure_mgmt_storage-19.0.0-py2.py3-none-any.whl (1.8 MB)\n",
            "Collecting argcomplete~=1.8\n",
            "  Downloading argcomplete-1.12.3-py2.py3-none-any.whl (38 kB)\n",
            "Collecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<4.0.0\n",
            "  Downloading cryptography-3.4.8-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
            "Collecting azure-core<1.21\n",
            "  Downloading azure_core-1.20.1-py2.py3-none-any.whl (177 kB)\n",
            "Collecting humanfriendly<10.0,>=4.7\n",
            "  Downloading humanfriendly-9.2-py2.py3-none-any.whl (86 kB)\n",
            "Collecting msrest<1.0.0,>=0.5.1\n",
            "  Downloading msrest-0.6.21-py2.py3-none-any.whl (85 kB)\n",
            "Collecting PyJWT<3.0.0\n",
            "  Downloading PyJWT-2.3.0-py3-none-any.whl (16 kB)\n",
            "Collecting urllib3<=1.26.7,>=1.23\n",
            "  Downloading urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n",
            "Collecting azure-mgmt-keyvault<10.0.0,>=0.40.0\n",
            "  Downloading azure_mgmt_keyvault-9.3.0-py2.py3-none-any.whl (412 kB)\n",
            "Collecting azure-graphrbac<1.0.0,>=0.40.0\n",
            "  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\n",
            "Collecting azure-mgmt-authorization<1.0.0,>=0.40.0\n",
            "  Downloading azure_mgmt_authorization-0.61.0-py2.py3-none-any.whl (94 kB)\n",
            "Collecting SecretStorage<4.0.0\n",
            "  Downloading SecretStorage-3.3.1-py3-none-any.whl (15 kB)\n",
            "Collecting contextlib2<22.0.0\n",
            "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
            "Collecting paramiko<3.0.0,>=2.0.8\n",
            "  Downloading paramiko-2.9.2-py2.py3-none-any.whl (210 kB)\n",
            "Collecting pkginfo\n",
            "  Downloading pkginfo-1.8.2-py2.py3-none-any.whl (26 kB)\n",
            "Collecting azure-mgmt-resource<20.0.0,>=15.0.0\n",
            "  Downloading azure_mgmt_resource-19.0.0-py2.py3-none-any.whl (2.2 MB)\n",
            "Collecting msrestazure<=0.6.4,>=0.4.33\n",
            "  Downloading msrestazure-0.6.4-py2.py3-none-any.whl (40 kB)\n",
            "Collecting azure-common<2.0.0,>=1.1.12\n",
            "  Downloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
            "Collecting msal<2.0.0,>=1.15.0\n",
            "  Downloading msal-1.16.0-py2.py3-none-any.whl (78 kB)\n",
            "Collecting backports.tempfile\n",
            "  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\n",
            "Collecting jmespath<1.0.0\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting msal-extensions<0.4,>=0.3.0\n",
            "  Downloading msal_extensions-0.3.1-py2.py3-none-any.whl (18 kB)\n",
            "Collecting pyopenssl<22.0.0\n",
            "  Downloading pyOpenSSL-21.0.0-py2.py3-none-any.whl (55 kB)\n",
            "Collecting docker<6.0.0\n",
            "  Downloading docker-5.0.3-py2.py3-none-any.whl (146 kB)\n",
            "Collecting adal<=1.2.7,>=1.2.0\n",
            "  Downloading adal-1.2.7-py2.py3-none-any.whl (55 kB)\n",
            "Collecting azure-mgmt-containerregistry>=2.0.0\n",
            "  Downloading azure_mgmt_containerregistry-9.0.0-py3-none-any.whl (937 kB)\n",
            "Collecting pathspec<1.0.0\n",
            "  Downloading pathspec-0.9.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting packaging<22.0\n",
            "  Downloading packaging-21.3-py3-none-any.whl (40 kB)\n",
            "Collecting ndg-httpsclient<=0.5.1\n",
            "  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\n",
            "Collecting cached-property; python_version < \"3.8\"\n",
            "  Downloading cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "Collecting werkzeug>=0.11.15\n",
            "  Downloading Werkzeug-2.0.2-py3-none-any.whl (288 kB)\n",
            "Collecting google-auth<2,>=1.6.3\n",
            "  Downloading google_auth-1.35.0-py2.py3-none-any.whl (152 kB)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /azureml-envs/azureml_cf7bc5a038f0d79aaaf5515c9290adf2/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow->-r /azureml-environment-setup/condaenv.bh1el8w5.requirements.txt (line 3)) (50.3.0.post20201006)\n",
            "Collecting tensorboard-plugin-wit>=1.6.0\n",
            "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "Collecting markdown>=2.6.8\n",
            "  Downloading Markdown-3.3.6-py3-none-any.whl (97 kB)\n",
            "Collecting distro>=1.2.0\n",
            "  Downloading distro-1.6.0-py2.py3-none-any.whl (19 kB)\n",
            "Collecting click>=5.1\n",
            "  Downloading click-8.0.3-py3-none-any.whl (97 kB)\n",
            "Collecting Jinja2>=2.10\n",
            "  Downloading Jinja2-3.0.3-py3-none-any.whl (133 kB)\n",
            "Collecting itsdangerous>=0.24\n",
            "  Downloading itsdangerous-2.0.1-py3-none-any.whl (18 kB)\n",
            "Collecting importlib-metadata; python_version < \"3.8\"\n",
            "  Downloading importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\n",
            "Collecting tabulate\n",
            "  Downloading tabulate-0.8.9-py3-none-any.whl (25 kB)\n",
            "Collecting pygments\n",
            "  Downloading Pygments-2.11.2-py3-none-any.whl (1.1 MB)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting pyyaml\n",
            "  Downloading PyYAML-6.0-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (603 kB)\n",
            "Collecting charset-normalizer~=2.0.0; python_version >= \"3\"\n",
            "  Downloading charset_normalizer-2.0.11-py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /azureml-envs/azureml_cf7bc5a038f0d79aaaf5515c9290adf2/lib/python3.6/site-packages (from requests[socks]<3.0.0,>=2.19.1->azureml-core~=1.37.0->azureml-defaults~=1.37.0->-r /azureml-environment-setup/condaenv.bh1el8w5.requirements.txt (line 2)) (2020.6.20)\n",
            "Collecting idna<4,>=2.5; python_version >= \"3\"\n",
            "  Downloading idna-3.3-py3-none-any.whl (61 kB)\n",
            "Collecting PySocks!=1.5.7,>=1.5.6; extra == \"socks\"\n",
            "  Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
            "Collecting azure-mgmt-core<2.0.0,>=1.2.0\n",
            "  Downloading azure_mgmt_core-1.3.0-py2.py3-none-any.whl (25 kB)\n",
            "Collecting cffi>=1.12\n",
            "  Downloading cffi-1.15.0-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (405 kB)\n",
            "Collecting requests-oauthlib>=0.5.0\n",
            "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
            "Collecting isodate>=0.6.0\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "Collecting jeepney>=0.6\n",
            "  Downloading jeepney-0.7.1-py3-none-any.whl (54 kB)\n",
            "Collecting pynacl>=1.0.1\n",
            "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
            "Collecting bcrypt>=3.1.3\n",
            "  Downloading bcrypt-3.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (61 kB)\n",
            "Collecting backports.weakref\n",
            "  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\n",
            "Collecting portalocker<3,>=1.0; python_version >= \"3.5\" and platform_system != \"Windows\"\n",
            "  Downloading portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n",
            "Collecting websocket-client>=0.32.0\n",
            "  Downloading websocket_client-1.2.3-py3-none-any.whl (53 kB)\n",
            "Collecting pyparsing!=3.0.5,>=2.0.2\n",
            "  Downloading pyparsing-3.0.7-py3-none-any.whl (98 kB)\n",
            "Collecting pyasn1>=0.1.1\n",
            "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
            "Collecting dataclasses; python_version < \"3.7\"\n",
            "  Downloading dataclasses-0.8-py3-none-any.whl (19 kB)\n",
            "Collecting cachetools<5.0,>=2.0.0\n",
            "  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\n",
            "Collecting rsa<5,>=3.1.4; python_version >= \"3.6\"\n",
            "  Downloading rsa-4.8-py3-none-any.whl (39 kB)\n",
            "Collecting pyasn1-modules>=0.2.1\n",
            "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
            "Collecting MarkupSafe>=2.0\n",
            "  Downloading MarkupSafe-2.0.1-cp36-cp36m-manylinux2010_x86_64.whl (30 kB)\n",
            "Collecting zipp>=0.5\n",
            "  Downloading zipp-3.6.0-py3-none-any.whl (5.3 kB)\n",
            "Collecting pycparser\n",
            "  Downloading pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
            "Collecting oauthlib>=3.0.0\n",
            "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
            "Building wheels for collected packages: fusepy, json-logging-py, clang, termcolor, wrapt\n",
            "  Building wheel for fusepy (setup.py): started\n",
            "  Building wheel for fusepy (setup.py): finished with status 'done'\n",
            "  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10504 sha256=f8752175a862f0ea2b94ddac72ac66f86e1c99b9e89935b8497b18b69b1bebb2\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/5c/83/1dd7e8a232d12227e5410120f4374b33adeb4037473105b079\n",
            "  Building wheel for json-logging-py (setup.py): started\n",
            "  Building wheel for json-logging-py (setup.py): finished with status 'done'\n",
            "  Created wheel for json-logging-py: filename=json_logging_py-0.2-py3-none-any.whl size=3924 sha256=c720c2f4bafc95ba9065405744f8cf6a4cd954173e17f1cc66acfa9bc487393f\n",
            "  Stored in directory: /root/.cache/pip/wheels/e2/1d/52/535a274b9c2ce7d4064838f2bdb62013801281ef7d7f21e2ee\n",
            "  Building wheel for clang (setup.py): started\n",
            "  Building wheel for clang (setup.py): finished with status 'done'\n",
            "  Created wheel for clang: filename=clang-5.0-py3-none-any.whl size=30705 sha256=12d5f3c927b62904f1227c7f40afd3f4740754ae9408b616b0d5e98f3434dbc3\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/4c/94/0583f60c9c5b6024ed64f290cb2d43b06bb4f75577dc3c93a7\n",
            "  Building wheel for termcolor (setup.py): started\n",
            "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
            "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4830 sha256=05cf64ad45d51c9c348f0135bfb72f39285ad69db3759d5bd3eaf358002cb20d\n",
            "  Stored in directory: /root/.cache/pip/wheels/93/2a/eb/e58dbcbc963549ee4f065ff80a59f274cc7210b6eab962acdc\n",
            "  Building wheel for wrapt (setup.py): started\n",
            "  Building wheel for wrapt (setup.py): finished with status 'done'\n",
            "  Created wheel for wrapt: filename=wrapt-1.12.1-cp36-cp36m-linux_x86_64.whl size=69873 sha256=eef5a05b8ef210c8aeffe0aec8dec78c309107ad0150176b47be63497e8d3529\n",
            "  Stored in directory: /root/.cache/pip/wheels/32/42/7f/23cae9ff6ef66798d00dc5d659088e57dbba01566f6c60db63\n",
            "Successfully built fusepy json-logging-py clang termcolor wrapt\n",
            "Installing collected packages: distro, dotnetcore2, azureml-dataprep-native, cloudpickle, azureml-dataprep-rslex, PyJWT, pycparser, cffi, cryptography, charset-normalizer, urllib3, idna, PySocks, requests, msal, portalocker, msal-extensions, six, azure-core, azure-identity, azureml-dataprep, numpy, pyarrow, fusepy, python-dateutil, pytz, pandas, azureml-dataset-runtime, wrapt, inference-schema, applicationinsights, gunicorn, typing-extensions, zipp, importlib-metadata, click, MarkupSafe, Jinja2, dataclasses, werkzeug, itsdangerous, flask, azureml-inference-server-http, json-logging-py, configparser, jsonpickle, tabulate, pygments, colorama, pyyaml, jmespath, argcomplete, knack, oauthlib, requests-oauthlib, isodate, msrest, azure-common, azure-mgmt-core, azure-mgmt-storage, humanfriendly, azure-mgmt-keyvault, adal, msrestazure, azure-graphrbac, azure-mgmt-authorization, jeepney, SecretStorage, contextlib2, pynacl, bcrypt, paramiko, pkginfo, azure-mgmt-resource, backports.weakref, backports.tempfile, pyopenssl, websocket-client, docker, azure-mgmt-containerregistry, pathspec, pyparsing, packaging, pyasn1, ndg-httpsclient, azureml-core, azureml-defaults, grpcio, opt-einsum, cached-property, h5py, clang, protobuf, keras-preprocessing, keras, cachetools, rsa, pyasn1-modules, google-auth, google-auth-oauthlib, tensorboard-data-server, tensorboard-plugin-wit, absl-py, markdown, tensorboard, termcolor, astunparse, gast, google-pasta, tensorflow-estimator, flatbuffers, tensorflow, joblib, threadpoolctl, scipy, scikit-learn, opencv-python-headless\n",
            "Successfully installed Jinja2-3.0.3 MarkupSafe-2.0.1 PyJWT-2.3.0 PySocks-1.7.1 SecretStorage-3.3.1 absl-py-0.15.0 adal-1.2.7 applicationinsights-0.11.10 argcomplete-1.12.3 astunparse-1.6.3 azure-common-1.1.28 azure-core-1.20.1 azure-graphrbac-0.61.1 azure-identity-1.7.0 azure-mgmt-authorization-0.61.0 azure-mgmt-containerregistry-9.0.0 azure-mgmt-core-1.3.0 azure-mgmt-keyvault-9.3.0 azure-mgmt-resource-19.0.0 azure-mgmt-storage-19.0.0 azureml-core-1.37.0.post2 azureml-dataprep-2.25.2 azureml-dataprep-native-38.0.0 azureml-dataprep-rslex-2.1.1 azureml-dataset-runtime-1.37.0 azureml-defaults-1.37.0 azureml-inference-server-http-0.4.2 backports.tempfile-1.0 backports.weakref-1.0.post1 bcrypt-3.2.0 cached-property-1.5.2 cachetools-4.2.4 cffi-1.15.0 charset-normalizer-2.0.11 clang-5.0 click-8.0.3 cloudpickle-1.6.0 colorama-0.4.4 configparser-3.7.4 contextlib2-21.6.0 cryptography-3.4.8 dataclasses-0.8 distro-1.6.0 docker-5.0.3 dotnetcore2-2.1.23 flask-1.0.3 flatbuffers-1.12 fusepy-3.0.1 gast-0.4.0 google-auth-1.35.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.43.0 gunicorn-20.1.0 h5py-3.1.0 humanfriendly-9.2 idna-3.3 importlib-metadata-4.8.3 inference-schema-1.3.0 isodate-0.6.1 itsdangerous-2.0.1 jeepney-0.7.1 jmespath-0.10.0 joblib-1.1.0 json-logging-py-0.2 jsonpickle-2.1.0 keras-2.6.0 keras-preprocessing-1.1.2 knack-0.8.2 markdown-3.3.6 msal-1.16.0 msal-extensions-0.3.1 msrest-0.6.21 msrestazure-0.6.4 ndg-httpsclient-0.5.1 numpy-1.19.5 oauthlib-3.2.0 opencv-python-headless-4.5.5.62 opt-einsum-3.3.0 packaging-21.3 pandas-1.1.5 paramiko-2.9.2 pathspec-0.9.0 pkginfo-1.8.2 portalocker-2.3.2 protobuf-3.19.4 pyarrow-3.0.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 pycparser-2.21 pygments-2.11.2 pynacl-1.5.0 pyopenssl-21.0.0 pyparsing-3.0.7 python-dateutil-2.8.2 pytz-2021.3 pyyaml-6.0 requests-2.27.1 requests-oauthlib-1.3.1 rsa-4.8 scikit-learn-0.24.2 scipy-1.5.4 six-1.15.0 tabulate-0.8.9 tensorboard-2.6.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.6.2 tensorflow-estimator-2.6.0 termcolor-1.1.0 threadpoolctl-3.1.0 typing-extensions-3.7.4.3 urllib3-1.26.7 websocket-client-1.2.3 werkzeug-2.0.2 wrapt-1.12.1 zipp-3.6.0\n",
            "\n",
            "done\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate /azureml-envs/azureml_cf7bc5a038f0d79aaaf5515c9290adf2\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n",
            "\u001b[91m\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "  current version: 4.9.2\n",
            "  latest version: 4.11.0\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c defaults conda\n",
            "\n",
            "\n",
            "\u001b[0mWARNING: /root/.conda/pkgs does not exist\n",
            "Removing intermediate container 453cb9a2df2b\n",
            " ---> 90b2db63af76\n",
            "Step 9/21 : ENV PATH /azureml-envs/azureml_cf7bc5a038f0d79aaaf5515c9290adf2/bin:$PATH\n",
            " ---> Running in e410b26d15b0\n",
            "Removing intermediate container e410b26d15b0\n",
            " ---> 3f7017442753\n",
            "Step 10/21 : COPY azureml-environment-setup/send_conda_dependencies.py azureml-environment-setup/send_conda_dependencies.py\n",
            " ---> a567013a2cd1\n",
            "Step 11/21 : RUN echo \"Copying environment context\"\n",
            " ---> Running in 8b23bc9e5774\n",
            "Copying environment context\n",
            "Removing intermediate container 8b23bc9e5774\n",
            " ---> b8f00d72687c\n",
            "Step 12/21 : COPY azureml-environment-setup/environment_context.json azureml-environment-setup/environment_context.json\n",
            " ---> 6f24ccdf8ffa\n",
            "Step 13/21 : RUN python /azureml-environment-setup/send_conda_dependencies.py -p /azureml-envs/azureml_cf7bc5a038f0d79aaaf5515c9290adf2\n",
            " ---> Running in ed40acf06abd\n",
            "Report materialized dependencies for the environment\n",
            "Reading environment context\n",
            "Exporting conda environment\n",
            "Sending request with materialized conda environment details\n",
            "Successfully sent materialized environment details\n",
            "Removing intermediate container ed40acf06abd\n",
            " ---> c68a6c3919ac\n",
            "Step 14/21 : ENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/azureml_cf7bc5a038f0d79aaaf5515c9290adf2\n",
            " ---> Running in e515e6b0d7d4\n",
            "Removing intermediate container e515e6b0d7d4\n",
            " ---> 21e8edb4f23d\n",
            "Step 15/21 : ENV LD_LIBRARY_PATH /azureml-envs/azureml_cf7bc5a038f0d79aaaf5515c9290adf2/lib:$LD_LIBRARY_PATH\n",
            " ---> Running in 3b5839c7c36f\n",
            "Removing intermediate container 3b5839c7c36f\n",
            " ---> 2e05f1efe19b\n",
            "Step 16/21 : ENV CONDA_DEFAULT_ENV=azureml_cf7bc5a038f0d79aaaf5515c9290adf2 CONDA_PREFIX=/azureml-envs/azureml_cf7bc5a038f0d79aaaf5515c9290adf2\n",
            " ---> Running in 6a660c0dd1c2\n",
            "Removing intermediate container 6a660c0dd1c2\n",
            " ---> 266c23d6415f\n",
            "Step 17/21 : COPY azureml-environment-setup/spark_cache.py azureml-environment-setup/log4j.properties /azureml-environment-setup/\n",
            " ---> 2c01641628b9\n",
            "Step 18/21 : RUN if [ $SPARK_HOME ]; then /bin/bash -c '$SPARK_HOME/bin/spark-submit  /azureml-environment-setup/spark_cache.py'; fi\n",
            " ---> Running in 7246d124d300\n",
            "Removing intermediate container 7246d124d300\n",
            " ---> cfa093d92150\n",
            "Step 19/21 : RUN rm -rf azureml-environment-setup\n",
            " ---> Running in 3da0844f5540\n",
            "Removing intermediate container 3da0844f5540\n",
            " ---> 9e2ccc18b434\n",
            "Step 20/21 : ENV AZUREML_ENVIRONMENT_IMAGE True\n",
            " ---> Running in 537e06f7c0e7\n",
            "Removing intermediate container 537e06f7c0e7\n",
            " ---> c0e735f157d5\n",
            "Step 21/21 : CMD [\"bash\"]\n",
            " ---> Running in 635b8ca3c643\n",
            "Removing intermediate container 635b8ca3c643\n",
            " ---> 96b725953e43\n",
            "Successfully built 96b725953e43\n",
            "Successfully tagged 4bc96a278283483f8523a427ca6960f3.azurecr.io/azureml/azureml_87ff35206cca7b761e09d4f06b1ec00b:latest\n",
            "Successfully tagged 4bc96a278283483f8523a427ca6960f3.azurecr.io/azureml/azureml_87ff35206cca7b761e09d4f06b1ec00b:1\n",
            "2022/02/05 13:54:08 Successfully executed container: acb_step_0\n",
            "2022/02/05 13:54:08 Executing step ID: acb_step_1. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
            "2022/02/05 13:54:08 Pushing image: 4bc96a278283483f8523a427ca6960f3.azurecr.io/azureml/azureml_87ff35206cca7b761e09d4f06b1ec00b:1, attempt 1\n",
            "The push refers to repository [4bc96a278283483f8523a427ca6960f3.azurecr.io/azureml/azureml_87ff35206cca7b761e09d4f06b1ec00b]\n",
            "36e5818f700b: Preparing\n",
            "52b6aa4e1bed: Preparing\n",
            "f47c7942215b: Preparing\n",
            "f7f679445fef: Preparing\n",
            "8b3202201dee: Preparing\n",
            "702629b9bc4d: Preparing\n",
            "29e20d2b0365: Preparing\n",
            "8438ad23cc7a: Preparing\n",
            "fa17dae0bf70: Preparing\n",
            "57815e05ae18: Preparing\n",
            "3c50432f3f31: Preparing\n",
            "311c5d6a5fbd: Preparing\n",
            "510d9bebb038: Preparing\n",
            "ae7a6b62e247: Preparing\n",
            "98fed88a80e7: Preparing\n",
            "e2015ea1a701: Preparing\n",
            "f7df5bbbf80f: Preparing\n",
            "17773ff7b0e9: Preparing\n",
            "824bf068fd3d: Preparing\n",
            "702629b9bc4d: Waiting\n",
            "29e20d2b0365: Waiting\n",
            "8438ad23cc7a: Waiting\n",
            "fa17dae0bf70: Waiting\n",
            "57815e05ae18: Waiting\n",
            "3c50432f3f31: Waiting\n",
            "311c5d6a5fbd: Waiting\n",
            "510d9bebb038: Waiting\n",
            "ae7a6b62e247: Waiting\n",
            "98fed88a80e7: Waiting\n",
            "e2015ea1a701: Waiting\n",
            "f7df5bbbf80f: Waiting\n",
            "17773ff7b0e9: Waiting\n",
            "824bf068fd3d: Waiting\n",
            "8b3202201dee: Pushed\n",
            "f7f679445fef: Pushed\n",
            "36e5818f700b: Pushed\n",
            "52b6aa4e1bed: Pushed\n",
            "f47c7942215b: Pushed\n",
            "fa17dae0bf70: Pushed\n",
            "29e20d2b0365: Pushed\n",
            "8438ad23cc7a: Pushed\n",
            "57815e05ae18: Pushed\n",
            "3c50432f3f31: Pushed\n",
            "311c5d6a5fbd: Pushed\n",
            "510d9bebb038: Pushed\n",
            "ae7a6b62e247: Pushed\n",
            "f7df5bbbf80f: Pushed\n",
            "e2015ea1a701: Pushed\n",
            "824bf068fd3d: Pushed\n",
            "98fed88a80e7: Pushed\n",
            "17773ff7b0e9: Pushed\n",
            "702629b9bc4d: Pushed\n",
            "1: digest: sha256:89fae7b346472f670429b69cfa01592bf4970ddb9b13c5819cd700fabc840ec2 size: 4307\n",
            "2022/02/05 13:55:59 Successfully pushed image: 4bc96a278283483f8523a427ca6960f3.azurecr.io/azureml/azureml_87ff35206cca7b761e09d4f06b1ec00b:1\n",
            "2022/02/05 13:55:59 Executing step ID: acb_step_2. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
            "2022/02/05 13:55:59 Pushing image: 4bc96a278283483f8523a427ca6960f3.azurecr.io/azureml/azureml_87ff35206cca7b761e09d4f06b1ec00b:latest, attempt 1\n",
            "The push refers to repository [4bc96a278283483f8523a427ca6960f3.azurecr.io/azureml/azureml_87ff35206cca7b761e09d4f06b1ec00b]\n",
            "36e5818f700b: Preparing\n",
            "52b6aa4e1bed: Preparing\n",
            "f47c7942215b: Preparing\n",
            "f7f679445fef: Preparing\n",
            "8b3202201dee: Preparing\n",
            "702629b9bc4d: Preparing\n",
            "29e20d2b0365: Preparing\n",
            "8438ad23cc7a: Preparing\n",
            "fa17dae0bf70: Preparing\n",
            "57815e05ae18: Preparing\n",
            "3c50432f3f31: Preparing\n",
            "311c5d6a5fbd: Preparing\n",
            "510d9bebb038: Preparing\n",
            "ae7a6b62e247: Preparing\n",
            "98fed88a80e7: Preparing\n",
            "e2015ea1a701: Preparing\n",
            "f7df5bbbf80f: Preparing\n",
            "17773ff7b0e9: Preparing\n",
            "824bf068fd3d: Preparing\n",
            "702629b9bc4d: Waiting\n",
            "29e20d2b0365: Waiting\n",
            "8438ad23cc7a: Waiting\n",
            "fa17dae0bf70: Waiting\n",
            "57815e05ae18: Waiting\n",
            "3c50432f3f31: Waiting\n",
            "311c5d6a5fbd: Waiting\n",
            "f7df5bbbf80f: Waiting\n",
            "17773ff7b0e9: Waiting\n",
            "510d9bebb038: Waiting\n",
            "ae7a6b62e247: Waiting\n",
            "824bf068fd3d: Waiting\n",
            "98fed88a80e7: Waiting\n",
            "e2015ea1a701: Waiting\n",
            "f47c7942215b: Layer already exists\n",
            "8b3202201dee: Layer already exists\n",
            "52b6aa4e1bed: Layer already exists\n",
            "702629b9bc4d: Layer already exists\n",
            "8438ad23cc7a: Layer already exists\n",
            "fa17dae0bf70: Layer already exists\n",
            "29e20d2b0365: Layer already exists\n",
            "57815e05ae18: Layer already exists\n",
            "3c50432f3f31: Layer already exists\n",
            "311c5d6a5fbd: Layer already exists\n",
            "510d9bebb038: Layer already exists\n",
            "ae7a6b62e247: Layer already exists\n",
            "98fed88a80e7: Layer already exists\n",
            "e2015ea1a701: Layer already exists\n",
            "f7df5bbbf80f: Layer already exists\n",
            "824bf068fd3d: Layer already exists\n",
            "17773ff7b0e9: Layer already exists\n",
            "f7f679445fef: Layer already exists\n",
            "36e5818f700b: Layer already exists\n",
            "latest: digest: sha256:89fae7b346472f670429b69cfa01592bf4970ddb9b13c5819cd700fabc840ec2 size: 4307\n",
            "2022/02/05 13:56:01 Successfully pushed image: 4bc96a278283483f8523a427ca6960f3.azurecr.io/azureml/azureml_87ff35206cca7b761e09d4f06b1ec00b:latest\n",
            "2022/02/05 13:56:01 Step ID: acb_step_0 marked as successful (elapsed time in seconds: 208.034648)\n",
            "2022/02/05 13:56:01 Populating digests for step ID: acb_step_0...\n",
            "2022/02/05 13:56:02 Successfully populated digests for step ID: acb_step_0\n",
            "2022/02/05 13:56:02 Step ID: acb_step_1 marked as successful (elapsed time in seconds: 110.279628)\n",
            "2022/02/05 13:56:02 Step ID: acb_step_2 marked as successful (elapsed time in seconds: 2.274753)\n",
            "2022/02/05 13:56:02 The following dependencies were found:\n",
            "2022/02/05 13:56:02 \n",
            "- image:\n",
            "    registry: 4bc96a278283483f8523a427ca6960f3.azurecr.io\n",
            "    repository: azureml/azureml_87ff35206cca7b761e09d4f06b1ec00b\n",
            "    tag: latest\n",
            "    digest: sha256:89fae7b346472f670429b69cfa01592bf4970ddb9b13c5819cd700fabc840ec2\n",
            "  runtime-dependency:\n",
            "    registry: mcr.microsoft.com\n",
            "    repository: azureml/openmpi3.1.2-ubuntu18.04\n",
            "    tag: 20211124.v1\n",
            "    digest: sha256:4a11079816df82134801c513f323799acad2cbef525ef7a5361278d9b74b1d14\n",
            "  git: {}\n",
            "- image:\n",
            "    registry: 4bc96a278283483f8523a427ca6960f3.azurecr.io\n",
            "    repository: azureml/azureml_87ff35206cca7b761e09d4f06b1ec00b\n",
            "    tag: \"1\"\n",
            "    digest: sha256:89fae7b346472f670429b69cfa01592bf4970ddb9b13c5819cd700fabc840ec2\n",
            "  runtime-dependency:\n",
            "    registry: mcr.microsoft.com\n",
            "    repository: azureml/openmpi3.1.2-ubuntu18.04\n",
            "    tag: 20211124.v1\n",
            "    digest: sha256:4a11079816df82134801c513f323799acad2cbef525ef7a5361278d9b74b1d14\n",
            "  git: {}\n",
            "\n",
            "Run ID: cb4 was successful after 5m26s\n"
          ]
        },
        {
          "ename": "ExperimentExecutionException",
          "evalue": "ExperimentExecutionException:\n\tMessage: The output streaming for the run interrupted.\nBut the run is still executing on the compute target. \nDetails for canceling the run can be found here: https://aka.ms/aml-docs-cancel-run\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"The output streaming for the run interrupted.\\nBut the run is still executing on the compute target. \\nDetails for canceling the run can be found here: https://aka.ms/aml-docs-cancel-run\"\n    }\n}",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/run.py\u001b[0m in \u001b[0;36mwait_for_completion\u001b[0;34m(self, show_output, wait_post_processing, raise_on_error)\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m                 self._stream_run_output(\n\u001b[0m\u001b[1;32m    842\u001b[0m                     \u001b[0mfile_handle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/run.py\u001b[0m in \u001b[0;36m_stream_run_output\u001b[0;34m(self, file_handle, wait_post_processing, raise_on_error)\u001b[0m\n\u001b[1;32m   1031\u001b[0m             \u001b[0mfile_handle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_before_polling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpoll_start_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_details\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_details\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# TODO use FileWatcher\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mExperimentExecutionException\u001b[0m              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_19789/4236209401.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# specify show_output to True for a verbose log\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mexperiment_runs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_completion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshow_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/run.py\u001b[0m in \u001b[0;36mwait_for_completion\u001b[0;34m(self, show_output, wait_post_processing, raise_on_error)\u001b[0m\n\u001b[1;32m    850\u001b[0m                                 \u001b[0;34m\"https://aka.ms/aml-docs-cancel-run\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 852\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mExperimentExecutionException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    853\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m             \u001b[0mrunning_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRUNNING_STATES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mExperimentExecutionException\u001b[0m: ExperimentExecutionException:\n\tMessage: The output streaming for the run interrupted.\nBut the run is still executing on the compute target. \nDetails for canceling the run can be found here: https://aka.ms/aml-docs-cancel-run\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"The output streaming for the run interrupted.\\nBut the run is still executing on the compute target. \\nDetails for canceling the run can be found here: https://aka.ms/aml-docs-cancel-run\"\n    }\n}"
          ]
        }
      ],
      "source": [
        "# specify show_output to True for a verbose log\n",
        "experiment_runs[0].wait_for_completion(show_output=True) "
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.1"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
